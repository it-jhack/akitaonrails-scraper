

Nassim Taleb, Benoît Mandelbrot devem estar, de maneira trágica, vendo essa crise com olhos muito diferentes de nós. Alguns devem estar cansados disso mas vou repetir novamente minha recomendação em ler as obras de ambos.

Veja este trecho do livro The Black Swan, de 2006, de Nassim Taleb:

A Globalização cria fragilidade interligada, ao mesmo tempo que reduz a volatilidade e dá aparência de estabilidade. Em outras palavras isso cria Cisnes Negros devastadores. Nunca antes vivemos sob a ameaça de colapso global. Instituições Financeiras continuam se mesclando em um número menor de bancos muito grandes. Quase todos os bancos estão inter-relacionados. Então a ecologia financeira está se acumulando em bancos gigantes, incestuosos, burocráticos – quando um cai, todos caem. O aumento da concentração entre bancos parece ter o efeito de fazer crises financeiras parecerem menos prováveis, mas quando acontecem eles tem efeitos muito mais globais em escala e nos atingem duramente. Nos movemos de uma ecologia diversificada de pequenos bancos, com políticas variadas de empréstimos, para um framework mais homogêneo de firmas onde todas se parecem umas com as outras. Verdade, agora temos menos defeitos, mas quando eles acontecem … eu tremo só de pensar.
A instituição patrocinada pelo governo, Fannie Mae, quando eu olhos seus riscos, parece estar montada num barril de dinamite, vulnerável ao menor soluço. Mas não se preocupem: eles tem grandes equipes de cientistas que consideram esses eventos “improváveis”.

Não, Nassim não é um profeta, um adivinho, bidu ou guru. Aliás, ele odiaria ser chamado de guru. Ele apenas fez uma observação baseada no que todos nós ignoramos: infelizmente nossa máquina humana é muito pobre para lidar com abstrações, por exemplo, com Aleatoriedade
Também não se trata de um argumento contra globalização ou outras baboseiras pseudo-socialistas. A parte importante mesmo é o segundo parágrafo da citação.


Isso já aconteceu antes
A Long Term Capital Management era a menina dos olhos do mundo financeiro. Um hedge fund americano formado em 1997, que tinha entre seus fundadores não apenas um, mas dois prêmios Nobel de Economia, Robert C. Merton e Myron Scholes. Eles acreditavam que tinham a matemática (cof gaussiana cof) que era capaz de prever qualquer tipo de eventos. Em 1998, a LTCM já devia USD 4.6 bilhões. A Crise Russa destruiu suas teorias gaussianas, que ignorava e subestimava completamente Cisnes Negros.
E você acha que as pessoas aprenderam a lição? Infelizmente nós somos mais teimosos do que isso: as teorias de Scholes e Merton são ensinadas nos cursos de economia até hoje.
Isso não é uma qualidade apenas do mundo econômico: diversas outras áreas aceitam e empregam teorias absurdas, sem fundamentos, sem resultados, e ainda assim tratados como se fossem as próximas grandes revoluções. As pessoas comuns se deixam enganar facilmente simplesmente por nomes, por credenciais. Enfim, se credencial valesse alguma coisa, um Nobel destruído em 1998 deveria querer dizer alguma coisa.
Eu costumo dizer o seguinte: empresas e charlatães que vendem metodologias (de qualquer tipo: financeira, recursos humanos, gestão, etc) tem o emprego mais fácil do mundo, basta serem bons vendedores.
Se seu cliente teve sucesso depois de implementar a tal metodologia: “viu só, vocês tiveram sucesso porque implementaram nossa metodologia revolucionária.” É claro que esse cliente passa a figurar como “case de sucesso” nos seus portfolios.
Se seu cliente fracassa depois de implementar a tal metodologia: “é claro que fracassou, vocês não implementaram exatamente como dissemos, faltou comprometimento das suas equipes. Não há nada errado com nossa metodologia e sim com vocês mesmos.” E, é óbvio, que esse cliente nunca vai aparecer no portfolio, afinal ninguém gosta de divulgar fracassos.
É muito fácil enganar as pessoas. E não olhe para o lado: você está implementando uma metodologia desse tipo hoje, eu sei!
Falseabilidade

As pessoas tem a péssima mania de fazer as perguntas erradas: “como saber se uma teoria é verdadeira?” Por isso mesmo também recebem as respostas erradas e isso leva à decisões mais erradas ainda.
Mais uma vez, como já disse inúmeras vezes em artigos anteriores, nós somos feitos para sermos enganados. Pior do que isso: conscientemente não exercemos nossas habilidades céticas.
Toda vez que vemos um “case de sucesso”, automaticamente aceitamos a teoria como sendo “verdadeira”. Ou de maneira ainda mais torta: “nunca ouvi falar de um caso de fracasso dessa metodologia, portanto ela só pode ser válida.” É o que a maioria dos “gerentes” e “executivos” conclui. Quantas vezes vamos precisar repetir isso?
Ausência de evidência não é evidência de ausência.
Hoje usamos muitos dados estatísticos para tomar decisões. Estatística é muito útil se usada da maneira correta. Mas quando usada da maneira errada, ela é um enorme desastre.
Vamos ver: “nos últimos 3 anos estamos crescendo 2% todo mês, portanto podemos concluir com certeza que vamos continuar crescendo 2% nos próximos meses.” Todo mundo já fez isso. Até que um Cisne Negro acontece e daí a desculpa é outra: “não sei o que aconteceu, foi um acidente, porque segundo os dados isso não deveria ter acontecido.”
Deixemos as coisas bem claras: um evento raro se chama raro justamente porque ele não acontece o tempo todo. E é exatamente esse tipo de evento raro, aleatório e imprevisível que costuma dar os prejuízos bilionários ou os ganhos bilionários, depende se você é do tipo gaussiano ou do tipo paretiano.
Mas retornando ao problema inicial: dados estatísticos do passado não são suficientes para assegurar a validade de uma teoria?
Óbvio que NÃO.
O que dados do passado podem fazer, no máximo, é assegurar a falseabilidade de uma teoria. Como Nassim explica em Fooled by Randomness, com dados do passado podemos sim provar que uma teoria é inválida, mas jamais poderemos provar que uma teoria é válida.
Por exemplo, hoje sabemos que as teorias da física clássica de Newton são inválidas, pois a Teoria da Relatividade de Einstein já as derrubou. Mas sabemos dentro de quais contextos a teoria clássica ainda pode ser usada e quando precisamos da relatividade. Boas teorias científicas são aquelas que permitem critérios para julgar sua falseabilidade, nunca sua validade.
Astrologia e outras pseudo-ciências são dogmáticas. Tudo que é dogmático deve ser automaticamente descreditado pois justamente impede qualquer tentativa de verificar sua falseabilidade. Essa é a assinatura dos charlatães.
O argumento que descrevi na sessão anterior é exatamente o que os charlatães fazem: se funcionou é graças à teoria, se não funcionou é porque você não aplicou a teoria corretamente. A previsão não deu certo apesar de Marte estar alinhado com Saturno porque na realidade ele estava “um pouquinho” fora de posição, caso contrário teria funcionado …
Nassim deu outro exemplo ótimo: “tenho feito um estudo sobre a vida de George Bush. Depois de 20 mil observações posso assegurar que em nenhuma delas ele morreu. Portanto posso afirmar com certeza, baseado nesses dados históricos, que Bush nunca morreu logo é imortal.”
Falácias

Ultimamente já dei várias dicas sobre coisas que vocês devem evitar: se estamos falando de gestão ou assuntos relacionados a controle – principalmente de pessoas – e coisas não mecânicas, e a teoria não leva Pareto em consideração, joguem fora.
Se o assunto oferece uma teoria mas não tem margens para avaliar sua falseabilidade, é charlatanismo, joguem fora.
Livros de auto-ajuda são assim mesmo: oferecem teorias floridas, cobertas de mel, empacotadas de forma atraentes. Mas ao contrário de teorias científicas, elas não nos deixam tentar provar que elas não funcionam, apenas afirmam que funcionam, citam vários “casos de sucesso” e escondem todas as tentativas fracassadas.
Desde o começo do mês passado tenho viajado para dar palestras toda semana e eu sempre passo na livraria do aeroporto ou da rodoviária. Prestando mais atenção, os livros que estão em destaque são exatamente desse tipo: charlatanismo barato. Se não todas, quase todas.
A teoria “bonita” só existe hoje simplesmente porque ainda não encontrou um Cisne Negro em seu caminho. “Ah, nunca vai acontecer pois nunca aconteceu até agora.” E é justamente por isso mesmo que tem, talvez, até mais chances de acontecer: porque nunca aconteceu!
Fiquem atentos às seguintes Falácias:

Falácia da Indução: é uma falácia onde a indução está errada. Indução significa que você está tentando encontrar princípios gerais a partir de fatos conhecidos.


Falácia Narrativa: é a criação de uma história post-hoc de tal forma que o evento pareça ter tido uma causa identificável.


Falácia Estatística Regressiva: acreditar que a probabilidade de eventos futuros é previsível examinando ocorrências de eventos passados.


Falácia Lúdica: acreditar que a aleatoriedade estruturada encontrada em jogos se parece com a aleatoriedade não-estruturada encontrada na vida. É o problema de confundir o mapa (modelo) com o território (realidade).

Essa última leva em consideração:

é impossível ter todas as informações
variações muito pequenas nos dados podem levar a um impacto enorme (Efeito Borboleta, sim ele acontece o tempo todo)
teorias/modelos baseados em dados empíricos são falhos, já que eventos que ainda não aconteceram não tem como ser levados em consideração

É o exemplo que Taleb explica: digamos que você está tirando bolinhas coloridas a partir de uma caixa tampada – sem que você veja. Você tira 5 bolinhas brancas e 5 bolinhas vermelhas e, a partir desses dados empíricos, chega à conclusão que “sempre vai sair 1 bolinha vermelha para cada 2 bolinhas retiradas.” Mas mal sabe você que no fundo da mesa existe um buraco e lá está um menino escondido. Ao ouvir você afirmar isso, ele começa a te dar mais bolinhas brancas que vermelhas. Essa é a realidade.
Exercitamos muito pouco nosso ceticismo. Não se trata de virar paranóico, mas sim de avaliar só um pouco melhor do que a forma medíocre que fazemos hoje.
Emoções

Como Malcolm Gladwell diz em Blink nós efetivamente tomamos decisões num piscar de olhos. Claro, ela será tanto melhor quanto melhor for nossa experiência, nosso conhecimento e nossas habilidades.
Taleb descreve uma experiência que foi realizada com uma pessoa que precisou operar o cérebro – por causa de um tumor – e por causa disso foi necessário retirar o trecho do cérebro que é responsável pelas nossas emoções. Todo o resto permaneceu intacto.
“Excelente!” – alguém poderia pensar: esta é uma pessoa 100% racional, que não deixará as emoções esbarrarem na razão. Você poderia deduzir que essa pessoa seria capaz de tomar decisões inteligentes e racionais.
Surpresa: essa pessoa se tornou totalmente incapaz de tomar qualquer decisão. Sequer conseguia se decidir levantar da cama. Os estudos feitos mostram que talvez nossas decisões sejam muito mais realizadas pela parte emocional do que racional, ao contrário do que imaginamos.
Quem já lidou com inteligência artificial chega à conclusão que nós, humanos, provavelmente temos que ter um mecanismo de aproximação, pois é simplesmente impossível levar todas as variáveis em consideração. O tempo para avaliar tudo que sabemos levaria tanto tempo que já teríamos sido extintos por outros predadores milênios atrás.
Decidir num piscar de olhos ou pior, tentar ser “racional”, tem suas vantagens e desvantagens. Pessoas de mente aberta, extremamente estudiosas, muito experientes em muitas áreas, com muitas habilidades e capacidades, provavelmente serão capazes de tomar muitas decisões certas muito rápido (algumas na sorte, algumas erradas). Mas pessoas de mente fechada, medíocres, tomarão muitas decisões erradas.
Exemplo de decisão errada: confiar em vendedores de pseudo-ciências.
Como Karl Popper diria: “não se deve levar a ciência a sério demais” – exatamente porque a ciência se permite estar errada, refinando-se com o tempo e, se você levar tudo a sério demais, se arrisca usar teorias que ainda não foram validadas como falsas e sua próxima decisão pode justamente ser o Cisne Negro que a falsificará.
Conclusão
Muito, mas muito cuidado com os especialistas. Sem querer denegrir todos os tipos de especialistas pois realmente existem muitos bons, mas especialistas de coisas abstratas e não tangíveis como “metodologias”, “economia”, e coisas do tipo, devem ser vistos com olhos suspeitos sempre! Uma boa credencial não torna uma teoria melhor ou pior, é apenas irrelevante.
Não deixe sua decisão ser viciada por teorias não-científicas (pseudo-ciência, superstição, astrologia, homeopatia, etc).
Novamente, leiam Taleb: o que ele diz é óbvio, mas por alguma razão todos nós ignoramos. Pouca gente de fato entende o que é aleatoriedade. Parem de ficar freneticamente assistindo a Bloomberg, de ficar atualizando seu navegador a cada 5 segundos para ver os índices financeiros, nada disso vai te ajudar: você já ignorou o Cisne Negro, você já perdeu.
Apenas para dar uma pontinha sobre filosofia Ágil, me parece bastante inteligente, por exemplo, de porque as metodologias Ágeis insistem tanto em Sprints/Iterações curtas. Eles sabem que é impossível prever o futuro de longo prazo, por isso mesmo prioriza-se o que é realmente importante e se tenta planejar apenas o curto prazo, apenas o que é efetivamente possível. As metodologias Ágeis me parecem especialmente feitos para se defender dos Cisnes Negros que ainda assombram as equipes de desenvolvimento tradicional de software, como expliquei no meu artigo anterior.
Todo mundo conheceu apenas cisnes brancos no passado e induz que não existem Cisnes Negros. Eis onde mora o perigo!
tags: off-topic principles economics chaos

